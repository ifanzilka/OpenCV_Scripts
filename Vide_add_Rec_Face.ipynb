{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled27.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM7MBIqQ4PaB"
      },
      "source": [
        "# Libary\n",
        "import dlib\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from imutils import face_utils\n",
        "\n",
        "# Libary from progress bar\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3RfPQgo-YGa"
      },
      "source": [
        "video_path = \"/content/for_GO_Asmus_mod.mp4\"\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7whRrd0B95E"
      },
      "source": [
        "def convert_and_trim_bb(image, rect):\n",
        "\t\"\"\"\n",
        "  вычисляем стратовые точки прямоугольника и его ширину с длиной\n",
        "  \"\"\"\n",
        "  \n",
        "  # extract the starting and ending (x, y)-coordinates of the\n",
        "\t# bounding box\n",
        "\tstartX = rect.left()\n",
        "\tstartY = rect.top()\n",
        "\tendX = rect.right()\n",
        "\tendY = rect.bottom()\n",
        "\t# ensure the bounding box coordinates fall within the spatial\n",
        "\t# dimensions of the image\n",
        "\tstartX = max(0, startX)\n",
        "\tstartY = max(0, startY)\n",
        "\tendX = min(endX, image.shape[1])\n",
        "\tendY = min(endY, image.shape[0])\n",
        "\t# compute the width and height of the bounding box\n",
        "\tw = endX - startX\n",
        "\th = endY - startY\n",
        "\t# return our bounding box coordinates\n",
        "\treturn (startX, startY, w, h)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veXR_AtmMSiN",
        "outputId": "799c206b-cd1b-4def-d64f-90bec1298a63"
      },
      "source": [
        "# Модели для обнаружение точек на лице\n",
        "os.system('wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2')\n",
        "os.system('bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPGufLzoLVn7"
      },
      "source": [
        "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQUJb3GcErAB"
      },
      "source": [
        "import imageio\n",
        "\n",
        "# Libary from progress bar\n",
        "from tqdm import tqdm\n",
        "\n",
        "def creator_video_from_list(image_list, output_name_video, fps_ = 30, reverse_ = False):\n",
        "  \"\"\"\n",
        "  @image_list -> массив картинок\n",
        "  @output_name_video -> название выходного видео\n",
        "  @fps_ -> количество кадров в секунду\n",
        "  @reverse_ -> включение обратного порядка в видео\n",
        "  \"\"\"\n",
        "  \n",
        "  writer = imageio.get_writer(output_name_video, fps = fps_)\n",
        "  if reverse_:\n",
        "    image_list.reverse()\n",
        "\n",
        "  for im in tqdm(image_list):\n",
        "    writer.append_data(im)\n",
        "\n",
        "  writer.close()\n",
        "  print('Success create video!!!')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7CYv3cgoqKQ",
        "outputId": "ccfb229c-5586-41b6-c818-9453b5d02abe"
      },
      "source": [
        "def get_count_cadr_video(path_video):\n",
        "  \"\"\"\n",
        "  Данная функция возвращает количество кадров в видеофайле\n",
        "  @path_video -> Путь до видеофайла\n",
        "  \"\"\"\n",
        "  \n",
        "  cnt = 0\n",
        "  \n",
        "  cap = cv2.VideoCapture(path_video)\n",
        "  \n",
        "  while (cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "      cnt += 1\n",
        "    else:\n",
        "      break  \n",
        "  return cnt\n",
        "\n",
        "cadr = get_count_cadr_video(video_path)\n",
        "print(cadr)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiQBio5vqQ0I"
      },
      "source": [
        "def find_and_print_face_in_image(image):\n",
        "  \n",
        "  \"\"\"\n",
        "  @image -> image\n",
        "  \"\"\"\n",
        "\n",
        "  detector = dlib.get_frontal_face_detector()\n",
        "  rects = detector(image)\n",
        "  ## Return start x,y  and w, h\n",
        "  boxes = [convert_and_trim_bb(image, r) for r in rects]\n",
        "  \n",
        "  color = (0, 255, 0)\n",
        "  thickness = 2\n",
        "\n",
        "  for (x, y, w, h) in boxes:\n",
        "    cv2.rectangle(image, (x, y), (x + w, y + h), color, thickness)      \n",
        "    #face = image_rgb[y:y + h, x:x + w]\n",
        "    #plt.imshow(face)\n",
        "  \n",
        "  #return first box\n",
        "  x1 = 0\n",
        "  x_w = 0\n",
        "  y1 = 0\n",
        "  y_h = 0\n",
        "  for (x, y, w, h) in boxes:\n",
        "    x1 = x\n",
        "    x_w = w\n",
        "    y1 = y\n",
        "    y_h = h\n",
        "    break\n",
        "\n",
        "  return x1,x_w, y1, y_h    \n",
        "  #plt.imshow(image)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6sQ7e-sNGpv"
      },
      "source": [
        "def find_and_print_point_face(image):\n",
        "  # конвертируем изображение в много оттенков серого\n",
        "  img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  \n",
        "  # вычисляем список рамок на каждое найденное лицо\n",
        "  rects = detector(img_gray, 0)\n",
        "  \n",
        "  # вычисляем ключевые точки\n",
        "  shape = predictor(img_gray, rects[0])\n",
        "        \n",
        "  shape = face_utils.shape_to_np(shape)\n",
        "\n",
        "  radius = 1\n",
        "  color = (0, 0, 255)\n",
        "  img_tmp = image\n",
        "  \n",
        "  for x, y in shape:\n",
        "    cv2.circle(img_tmp, (x, y), radius, color , -1)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kETo7XczR6UV"
      },
      "source": [
        "import os\n",
        "os.system(\"pip install ffmpeg-python\")\n",
        "import ffmpeg\n",
        "\n",
        "def add_audio(video_path, audio_path, name):\n",
        "  input = ffmpeg.input(audio_path)\n",
        "  audio = input.audio\n",
        "\n",
        "  input2 = ffmpeg.input(video_path)\n",
        "  video = input2.video\n",
        "  \n",
        "  out = ffmpeg.output(audio, video, name)\n",
        "  out.run()\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIm5zCx6Qw05"
      },
      "source": [
        "def add_face_in_video(video_path, new_name):\n",
        "  \n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "  frame_width = int(cap.get(3))   #1216\n",
        "\n",
        "  frame_height = int(cap.get(4))  #2160\n",
        "\n",
        "\n",
        "  fps = int(cap.get(5))           # 25\n",
        "\n",
        "  count_cadr = get_count_cadr_video(video_path)\n",
        "\n",
        "  #### READ VIDEO ####\n",
        "\n",
        "  cnt = 0\n",
        "\n",
        "  x1 = 0\n",
        "  x_w = 0\n",
        "  y1 = 0\n",
        "  y_h = 0\n",
        "\n",
        "  images = []\n",
        "  for i in tqdm(range(count_cadr)):\n",
        "\n",
        "      if (cap.isOpened() == False):\n",
        "        break\n",
        "    \n",
        "      # capture each frame of the video\n",
        "      # frame -> img in BGR color\n",
        "\n",
        "      ret, frame = cap.read()\n",
        "   \n",
        "      if ret:\n",
        "\n",
        "          ### Перевод изображения в RGB\n",
        "          image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "          ### face in image ###\n",
        "          if cnt == 0:\n",
        "            x1, x_w, y1, y_h = find_and_print_face_in_image(image_rgb)\n",
        "          else:\n",
        "              find_and_print_face_in_image(image_rgb)\n",
        "          \n",
        "\n",
        "          ### face point\n",
        "          find_and_print_point_face(image_rgb)\n",
        "\n",
        "          delta = 100\n",
        "          sub_img = image_rgb[y1 - delta : y1 + y_h + delta, x1 - delta: x1+ x_w + delta]\n",
        "          #plt.imshow(sub_img)\n",
        "          \n",
        "\n",
        "          images.append(sub_img)\n",
        "          cnt += 1\n",
        "      else:\n",
        "        break    \n",
        "\n",
        "  print(cnt)\n",
        "  creator_video_from_list(images, new_name, fps_ = fps )\n",
        "  add_audio(new_name, video_path, 'a_' + new_name)\n",
        "\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4-cEj3MRl6c",
        "outputId": "4ac7bf55-ecef-4991-a2d8-fc0bbb6fa581"
      },
      "source": [
        "add_face_in_video(\"/content/for_GO_Asmus_mod.mp4\", \"new_video2.mp4\")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 347/347 [08:08<00:00,  1.41s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "347\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/347 [00:00<?, ?it/s]WARNING:root:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (380, 380) to (384, 384) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to None (risking incompatibility). You may also see a FFMPEG warning concerning speedloss due to data not being aligned.\n",
            "100%|██████████| 347/347 [00:03<00:00, 86.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Success create video!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFNKEGb5uBBW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}